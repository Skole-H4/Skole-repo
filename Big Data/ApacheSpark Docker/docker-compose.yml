services:
  spark-master:
    image: spark:python3
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_PUBLIC_DNS=localhost
    command: ["/opt/spark/sbin/start-master.sh", "-h", "spark-master"]
    ports:
      - "7077:7077"  # cluster
      - "8080:8080"  # Master UI
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    networks: [spark-net]

  spark-worker-1:
    image: spark:python3
    container_name: spark-worker-1
    depends_on: [spark-master]
    hostname: spark-worker-1
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - SPARK_PUBLIC_DNS=localhost
    command: ["/opt/spark/sbin/start-worker.sh", "spark://spark-master:7077"]
    ports:
      - "8081:8081"  # Worker UI
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    networks: [spark-net]

  spark-client:
    image: spark:python3
    container_name: spark-client
    depends_on: [spark-master]
    working_dir: /opt/spark-apps
    entrypoint: ["/bin/bash", "-lc", "tail -f /dev/null"]
    ports:
      - "4040:4040"  # job UI (når et job kører)
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    networks: [spark-net]

networks:
  spark-net:
    driver: bridge
